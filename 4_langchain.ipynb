{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMBJJBAPbs9xa586dPH2geG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThisIsFarhan/Language_Models/blob/main/4_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mupzq4uIbm_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42caf0ae-8b27-47d9-ab3d-07e8b47d5dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting llama-cpp-python==0.2.69\n",
            "  Downloading llama_cpp_python-0.2.69.tar.gz (42.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.2.69) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.2.69) (1.26.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.69)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.2.69) (3.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.69) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.69-cp311-cp311-linux_x86_64.whl size=55723569 sha256=1d9d381385940f962c4ba9d7f50c9b59283361912d5e5989c055738fe774b14d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1b/ff/b4dba97fbd16e731705b262602ba8f3b672bf4bde54ea0c104\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.69\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain>=0.1.17 transformers>=4.40.1 datasets>=2.18.0 accelerate>=0.27.2 sentence-transformers>=2.5.1 langchain_community\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python==0.2.69"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAGg4R-Eby7Q",
        "outputId": "dd9dc03f-6d18-4396-f654-0aaf08058618"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-29 20:01:26--  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.61, 3.165.160.11, 3.165.160.12, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1738184486&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczODE4NDQ4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=ZkHcSJWDZ0zXNOIwZ8A7230FQCDOCiBiVDrWn11%7ESpaGpZVQ5o2O7HGEkPDU2YCg2hovFx9LgZd02YHDoV-ER0-CNbXyp5LJiW-5b7lIch9sQAAHzz17q8ttMJPAjI23qMHq87CljbDfaI-gZXEFrE%7Em1rZHDH%7EKIAX34eykdpRkUt5o0H1evDIfc2GsR5jIzA9UcEgU6JBb53kPIAGGpvR-rt7OcX%7ETFFx1VWfsBwGMgtLU93w4e-3Jm7VUHv-OKI2jx-gakthW7TAiLjRy8wPYEBMjKRtvsY4pPRu%7E%7EyecKFu8Mg34MBG5YD%7EBnugZHBrLxRUUwofrrKnT4HXzyw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-01-29 20:01:26--  https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1738184486&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczODE4NDQ4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=ZkHcSJWDZ0zXNOIwZ8A7230FQCDOCiBiVDrWn11%7ESpaGpZVQ5o2O7HGEkPDU2YCg2hovFx9LgZd02YHDoV-ER0-CNbXyp5LJiW-5b7lIch9sQAAHzz17q8ttMJPAjI23qMHq87CljbDfaI-gZXEFrE%7Em1rZHDH%7EKIAX34eykdpRkUt5o0H1evDIfc2GsR5jIzA9UcEgU6JBb53kPIAGGpvR-rt7OcX%7ETFFx1VWfsBwGMgtLU93w4e-3Jm7VUHv-OKI2jx-gakthW7TAiLjRy8wPYEBMjKRtvsY4pPRu%7E%7EyecKFu8Mg34MBG5YD%7EBnugZHBrLxRUUwofrrKnT4HXzyw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.165.160.20, 3.165.160.77, 3.165.160.38, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.165.160.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7643295904 (7.1G) [binary/octet-stream]\n",
            "Saving to: ‘Phi-3-mini-4k-instruct-fp16.gguf’\n",
            "\n",
            "Phi-3-mini-4k-instr 100%[===================>]   7.12G  40.0MB/s    in 3m 1s   \n",
            "\n",
            "2025-01-29 20:04:28 (40.2 MB/s) - ‘Phi-3-mini-4k-instruct-fp16.gguf’ saved [7643295904/7643295904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LlamaCpp\n",
        "\n",
        "# Make sure the model path is correct for your system!\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"Phi-3-mini-4k-instruct-fp16.gguf\",\n",
        "    n_gpu_layers=-1,\n",
        "    max_tokens=500,\n",
        "    n_ctx=2048,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "2lks9uxjcy-z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chains"
      ],
      "metadata": {
        "id": "dCvThFdgcesf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate"
      ],
      "metadata": {
        "id": "hIshxnBadsJm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Single chain\n",
        "\n",
        "\n",
        "template = \"\"\"<s><|User|>\n",
        "{input_prompt}<|END|>\n",
        "<|Assistant|>\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"input_prompt\"]\n",
        ")\n",
        "\n",
        "basic_chain = prompt | llm\n",
        "basic_chain.invoke({\n",
        "    \"input_prompt\":\"Tell me about computer engineering\"\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "6JWrKE0Zc5v0",
        "outputId": "d3f03555-953b-48e7-f0bd-a04ddb25fc99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Computer Engineering is an interdisciplinary branch of engineering that integrates principles from electrical engineering and computer science. It's focused on the design, development, testing, and manufacturing of both hardware (physical parts) and software for computers, servers, storage devices, mobile phones, tablets, embedded systems in appliances and vehicles etc.\\n\\nComputer engineers work to develop new technology that makes existing devices faster or smaller but more powerful, as well as developing entirely new technologies like quantum computing. They also focus on improving the security of these technologies and designing efficient algorithms for processing data.\\n\\nThe field is continually evolving due to rapid advancements in digital technology. Computer engineering requires a solid understanding of both hardware and software elements, so many professionals hold degrees in electrical or computer science. \\n\\nKey sub-fields within computer engineering include:\\n\\n1. Embedded Systems Engineering: This involves designing systems that are part of larger devices but have specialized functions (like sensors for a smartphone).\\n2. Computer Architecture: The process of designing the structure and organization of a computer system, including its hardware components like CPUs and memory units.\\n3. Digital Signal Processing: This area involves manipulation of signals (like audio or video data) in digital format to enhance quality or extract information.\\n4. Telecommunication Engineering: Involves the transmission of information over distances for use in computing systems, such as cellular networks or internet services.\\n5. Network and Computer Security: This is about securing computer systems from cyber threats through various techniques like cryptography and intrusion detection systems.\\n6. Software Development: Computer engineers also work on creating software that runs the hardware components of a system, such as operating systems or applications.\\n\\nIn short, computer engineering involves a combination of electrical engineering to create and improve physical devices, and information technology knowledge for programming and designing complex software systems. \\n\\nThe field is vast with numerous opportunities in research, development, product management, quality assurance and more. The demand for professionals in this area continues to grow as we become more reliant on digital technologies.\\n\\nHere are a few questions you could ask about computer engineering:\\n1. How do the principles of electrical engineering contribute to the design of computer hardware?\\n2. Can you\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiple chain\n",
        "from langchain import LLMChain\n",
        "\n",
        "#--------------------Templates------------------------------\n",
        "summary_template = \"\"\"<s><|user|>\n",
        "Create a title for a story about {summary}. Only return the one-liner title.<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "summary_prompt = PromptTemplate(template=summary_template, input_variables=[\"summary\"])\n",
        "title = LLMChain(llm=llm, prompt=summary_prompt, output_key=\"title\")\n",
        "\n",
        "title_template = \"\"\"<s><|user|>\n",
        "Describe the main character of a story about {summary} with the title {title}. Use only two sentences.<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "title_prompt = PromptTemplate(\n",
        "    template=title_template, input_variables=[\"summary\", \"title\"]\n",
        ")\n",
        "character = LLMChain(llm=llm, prompt=title_prompt, output_key=\"character\")\n",
        "\n",
        "story_template = \"\"\"<s><|user|>\n",
        "Create a story about {summary} with the title {title}. The main charachter is: {character}. Only return the story and it cannot be longer than one paragraph<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "story_prompt = PromptTemplate(\n",
        "    template=story_template, input_variables=[\"summary\", \"title\", \"character\"]\n",
        ")\n",
        "story = LLMChain(llm=llm, prompt=story_prompt, output_key=\"story\")\n",
        "\n",
        "\n",
        "#Defining the chain\n",
        "llm_chain = title | character | story\n",
        "\n",
        "\n",
        "#invokation\n",
        "llm_chain.invoke(\"A person developing an efficient AI agent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9-wDt-_dZxK",
        "outputId": "9585b767-fd92-4229-befe-cf76ebf02cf0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': 'A person developing an efficient AI agent',\n",
              " 'title': ' \"Crafting Intelligence: The Odyssey of Building an Efficient AI Agent\"',\n",
              " 'character': \" The protagonist, Dr. Amelia Chen, is a brilliant and driven computer scientist who tirelessly works to develop an advanced artificial intelligence capable of learning and adapting with unprecedented efficiency. With unwavering determination and innovative problem-solving skills, she navigates the challenges of AI design while grappling with ethical concerns surrounding her creation's potential impact on society.\\n\\nDr. Amelia Chen is a compassionate yet fiercely independent researcher who brings together an interdisciplinary team to tackle complex problems in artificial intelligence, striving for balance between technological advancements and responsible use of technology. Her journey unfolds as she discovers the immense power her efficient AI agent holds, forcing her to confront difficult choices about how to wield this newfound knowledge for the benefit of humanity while preserving our values and morals.\",\n",
              " 'story': ' In \"Crafting Intelligence: The Odyssey of Building an Efficient AI Agent,\" Dr. Amelia Chen, a visionary computer scientist with unwavering determination, embarks on a transformative quest to engineer an advanced artificial intelligence that can learn and adapt at astonishing rates. With her team comprising diverse experts in ethics, machine learning, and cognitive science, she pioneers groundbreaking methodologies, meticulously navigating the labyrinth of innovation while ensuring responsible stewardship of AI\\'s potential. As her creation evolves beyond expectations, Dr. Chen faces profound dilemmas about its role in society, ultimately choosing to harness this powerful intellect as a force for positive change and human advancement, embodying the delicate balance between technological progress and moral integrity.'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}