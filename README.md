# Hugging Face Phi-3 Mini Model Example

This repository demonstrates how to use the `microsoft/Phi-3-mini-4k-instruct` model from Hugging Face for tokenization, encoding, decoding, and text generation. The code includes examples of tokenizing words and sentences, decoding tokenized data back to text, and building an interactive chatbot powered by the Phi-3 model.  

The chatbot uses a pre-defined system message and generates responses based on user input. To stop the chatbot, type "exit."  

Ensure you have a GPU-enabled machine to run the code efficiently.  

## Requirements
- Python 3.8+
- PyTorch with CUDA
- Hugging Face Transformers library

## How to Run
1. Clone this repository.
3. Run the jupyter notebook.
